{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of learning database from a stochastic reactors simulation\n",
    "\n",
    "This notebook builds a database to be used as a training database for the ML algorithm. In order for this script to be used, a stochastic reactors simulation with *build_ML_dtb=True* must have neen run beforehand. This simulation produces files *X.csv* and *Y.csv* with raw states $T$, $Y_k$ and necessary information to clusterize the data (e.g. progress variable). \n",
    "\n",
    "The current script generate the final database and enables to choose several options:\n",
    "\n",
    "+ Prediction of $Y_k(t+dt)$ or $Y_k(t+dt)-Y_k(t)$\n",
    "\n",
    "+ Application of a transform such as logarithm or Box-Cox\n",
    "\n",
    "+ Possibility to apply a temperature threshold to the data to avoid non-reacting zones\n",
    "\n",
    "+ Possibility to clusterize the data based on (i) k-means algorithm; (ii) progress variable values.\n",
    "\n",
    "Files *X_train*, *Y_train*, *X_val* and *Y_val* are created for each cluster. Note that if no clustering is applied, the default single cluster is cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_reacting_flows.stochastic_reactors_data_gen.database_processing import LearningDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the database processing are first set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store data processing parameters\n",
    "dtb_processing_parameters = {}\n",
    "\n",
    "dtb_processing_parameters[\"dtb_folder\"] = \"../scripts/STOCH_DTB_PREMIXED_CH4_TEST\"       # Stochastic reactors simulation folder\n",
    "dtb_processing_parameters[\"database_name\"] = \"database_1\"                   # Resulting database name\n",
    "dtb_processing_parameters[\"log_transform\"] = 0              # 0: no transform, 1: Logarithm transform, 2: Box-Cox transform\n",
    "dtb_processing_parameters[\"threshold\"] = 1.0e-10            # Threshold to be applied in case of logarithm transform\n",
    "dtb_processing_parameters[\"output_omegas\"] = True           # True: output differences, False: output mass fractions\n",
    "dtb_processing_parameters[\"detailed_mechanism\"] = \"/work/mehlc/2_IA_KINETICS/ai_reacting_flows/data/chemical_mechanisms/mech_H2.yaml\"        # Mechanism used for the database generation (/!\\ YAML format)\n",
    "dtb_processing_parameters[\"fuel\"] = \"H2\"           # Fuel name\n",
    "dtb_processing_parameters[\"with_N_chemistry\"] = False        # Considering Nitrogen chemistry or not (if not, N not considered in atom balance for reduction). In MLP, it will change treatment of N2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is then created as a *LearningDatabase* object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = LearningDatabase(dtb_processing_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply a temperature threshold if needed, here $600$ K for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.apply_temperature_threshold(600.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the possibility to apply ANN only to a reduced subset of species. In order to preserve atomic masses and enthalpy, a set of fictive species is added to the database. Their mass fractions are computed so that conservation of quantities is ensured. In order for the problem to have a solution, the following rules must be obeyed when selecting the fictive species:\n",
    "\n",
    "+ The number of fictive species must be *number of atoms + 1* (for the enthalpy). At the moment, the number of atoms is 4 ($C$, $H$, $O$, $N$), except for $H_2$, where carbon is not considered. Another possibility is to discard $N$, this is done by setting the *with_N_chemistry* parameter above to *False*.\n",
    "\n",
    "+ Each atom must be represented at least once.\n",
    "\n",
    "The reduction operation can be done with the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fictive_species = [\"O2\", \"H2O\", \"H2\"]\n",
    "subset_species = [\"H2\", \"O2\", \"N2\", \"H2O\"]\n",
    "database.reduce_species_set(subset_species, fictive_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can for instance check that the sum of species mass fractions is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(database.X[subset_species + [spec+\"_F\" for spec in fictive_species]].sum(axis=1))\n",
    "print(\"\")\n",
    "print(database.Y[subset_species + [spec+\"_F\" for spec in fictive_species]].sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the check for the sum being 1 is here just illustrative, as an advanced verification on the individual atomic mass fractions and the enthalpy is made in the *reduce_species_set* routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clusterize the dataset based on a progress variable if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database.clusterize_dataset(\"progvar\", 2, c_bounds=[0,0.95,1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could have used k-means: (commented because double clustering is banned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.clusterize_dataset(\"kmeans\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the size of the database (count made for each cluster):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.print_data_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can under-sample a given cluster (example: if the burnt gas cluster has too many states, we can reduce it). Here, we keep ratio_to_keep*size of cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.undersample_cluster(1, ratio_to_keep = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the under-sampling has been applied correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.print_data_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the database is processed in order ot be used in ML pipeline: (useless dataframe columns are suppressed and the transformation of the data is performed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.process_database(plot_distributions = True, distribution_species=[\"CH4\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94b4dddc39e3f97076cc987d98550b593fdb7c2e07b1ccd50e3fa5b10ed48d31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
