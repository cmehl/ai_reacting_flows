{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN model generation\n",
    "\n",
    "This notebook shows how to generate a ML model for chemical kinetics prediction. It assumes a processed database is available. See the notebook *generate_ML_dtb.ipynb* to get more information.\n",
    "\n",
    "The training is here done consecutively for several clusters, defined in the database generation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_reacting_flows.ann_model_generation.MLP_model import MLPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training parameters are first defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with parameters\n",
    "training_parameters = {}\n",
    "\n",
    "training_parameters[\"model_name_suffix\"] = \"TEST\"    # Name of the resulting model folder (as a suffix of MODEL)\n",
    "    \n",
    "training_parameters[\"dataset_path\"] = \"/work/mehlc/2_IA_KINETICS/ai_reacting_flows/scripts/STOCH_DTB_H2_DEV/database_1\"    # path of the database\n",
    "    \n",
    "training_parameters[\"dt_simu\"] = 5.0e-07     # Time step of the prediction\n",
    "    \n",
    "training_parameters[\"fuel\"] = \"H2\"           # Fuel\n",
    "training_parameters[\"mechanism_type\"] = \"detailed\"    # Mechanism type for ANN chemistry: detailed or reduced\n",
    "\n",
    "training_parameters[\"remove_N2\"] = True    # if True, N2 is removed from the neural network prediction\n",
    "\n",
    "training_parameters[\"nb_units_in_layers_list\"] = [[20,20]]   # Network shape: number of units in each layer\n",
    "training_parameters[\"layers_activation_list\"] = [['tanh','tanh']]    # Activation functions\n",
    "training_parameters[\"layers_type\"] = \"resnet\"               # \"dense\" or \"resnet\"\n",
    "\n",
    "\n",
    "training_parameters[\"batch_size\"] = 512         # Batch size for the gradient descent\n",
    "training_parameters[\"initial_learning_rate\"] = 1.0e-2           # Initial learnign rate\n",
    "training_parameters[\"decay_steps\"] = 100        # Exponential decay: done each decay_steps\n",
    "training_parameters[\"decay_rate\"] = 0.92        # Exponential decay: rate\n",
    "training_parameters[\"staircase\"] = True         # Stair case or continuous\n",
    "\n",
    "training_parameters[\"alpha_reg\"] = 0.0    # L2 regularization coefficient\n",
    "        \n",
    "training_parameters[\"epochs_list\"] = [5]    # number of epochs for each cluster\n",
    "\n",
    "\n",
    "training_parameters[\"hard_constraints_model\"] = 0   # Hard constraint: 0=no constraints, 1=constraints on atomic balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLPModel(training_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models for each clusters are trained in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.train_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94b4dddc39e3f97076cc987d98550b593fdb7c2e07b1ccd50e3fa5b10ed48d31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
